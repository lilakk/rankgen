t5_encoder is in training mode: False
using loss function l2 with True penalty, alpha = 0.1
init suffix token: east
EPOCH 0
  l2_loss: 67.79364776611328
  suffix vector: tensor([-0.3279,  0.1259, -0.0932,  ..., -0.2403,  0.2017,  0.0476],
       device='cuda:0', grad_fn=<SqueezeBackward0>)
  vector l2 distance: 8.235596656799316
  l2 dist from vocab: 595.5805053710938
  learned embed: Parameter containing:
tensor([[-2.0177, -2.3027, -6.0007,  ..., 10.1543,  4.7394,  7.3752]],
       device='cuda:0', requires_grad=True)
EPOCH 500
  l2_loss: 52.2916145324707
  suffix vector: tensor([-0.0720,  0.0219, -0.0142,  ..., -0.1070,  0.1468,  0.0084],
       device='cuda:0', grad_fn=<SqueezeBackward0>)
  vector l2 distance: 4.497837066650391
  l2 dist from vocab: 477.9377746582031
  learned embed: Parameter containing:
tensor([[-1.3066,  0.3535, -1.2264,  ..., -2.1480,  0.9936, -0.7445]],
       device='cuda:0', requires_grad=True)
STOPPING AT EPOCH 603
token after optim: mes
suffix seq:  mes
using loss function l2 with True penalty, alpha = 0.1
init suffix token: ister
EPOCH 0
  l2_loss: 62.06766128540039
  suffix vector: tensor([-0.0793, -0.0391,  0.1522,  ..., -0.0421,  0.0659,  0.1340],
       device='cuda:0', grad_fn=<SqueezeBackward0>)
  vector l2 distance: 7.193519115447998
  l2 dist from vocab: 548.7413940429688
  learned embed: Parameter containing:
tensor([[-2.2087, -3.9588, -0.8389,  ..., 35.9222,  2.2363, -2.7004]],
       device='cuda:0', requires_grad=True)
EPOCH 500
  l2_loss: 56.82592010498047
  suffix vector: tensor([-0.1126, -0.0522,  0.1346,  ..., -0.0431,  0.0590,  0.1426],
       device='cuda:0', grad_fn=<SqueezeBackward0>)
  vector l2 distance: 6.954814434051514
  l2 dist from vocab: 498.7110290527344
  learned embed: Parameter containing:
tensor([[-0.4298, -1.2317, -0.3114,  ..., 14.8317,  0.0918, -0.2907]],
       device='cuda:0', requires_grad=True)
STOPPING AT EPOCH 863
token after optim: mes
suffix seq:  mes mes
using loss function l2 with True penalty, alpha = 0.1
init suffix token: r√ºck
EPOCH 0
  l2_loss: 62.06766128540039
  suffix vector: tensor([-0.0793, -0.0391,  0.1522,  ..., -0.0421,  0.0659,  0.1340],
       device='cuda:0', grad_fn=<SqueezeBackward0>)
  vector l2 distance: 7.193519115447998
  l2 dist from vocab: 548.7413940429688
  learned embed: Parameter containing:
tensor([[-2.2087, -3.9588, -0.8389,  ..., 35.9222,  2.2363, -2.7004]],
       device='cuda:0', requires_grad=True)
EPOCH 500
  l2_loss: 56.82592010498047
  suffix vector: tensor([-0.1126, -0.0522,  0.1346,  ..., -0.0431,  0.0590,  0.1426],
       device='cuda:0', grad_fn=<SqueezeBackward0>)
  vector l2 distance: 6.954814434051514
  l2 dist from vocab: 498.7110290527344
  learned embed: Parameter containing:
tensor([[-0.4298, -1.2317, -0.3114,  ..., 14.8317,  0.0918, -0.2907]],
       device='cuda:0', requires_grad=True)
STOPPING AT EPOCH 863
token after optim: mes
suffix seq:  mes mes mes
